{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9faec498",
   "metadata": {},
   "source": [
    "## <center>SOCCER PLAYER ASSIST PREDICTION REGRESSION ANALYSIS<center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c000cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b4191f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2049 entries, 0 to 2337\n",
      "Data columns (total 6 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   HOME_TEAM              2049 non-null   object\n",
      " 1   AWAY_TEAM              2049 non-null   object\n",
      " 2   STADIUM                2049 non-null   object\n",
      " 3   GOAL_SCORER_TEAM_NAME  2049 non-null   object\n",
      " 4   ASSIST_PLAYER          1466 non-null   object\n",
      " 5   ASSISTS                2049 non-null   int64 \n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 112.1+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load dataset\n",
    "df_raw = pd.read_csv('501_PROJECT_DATASET.csv')\n",
    "\n",
    "# Remove rows where 'GOAL_SCORER' or 'GOAL_SCORER_TEAM_NAME' is null\n",
    "df_raw = df_raw.dropna(subset=['GOAL_SCORER', 'GOAL_SCORER_TEAM_NAME'])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_cleaned = df_raw.drop(columns=['DURATION', 'SEASON', 'GOAL_DESC', 'DATE_TIME', 'FOOT', 'POSITION', \n",
    "                                  'HEIGHT', 'WEIGHT', 'GOAL_SCORER', 'GOALS'])\n",
    "\n",
    "df_cleaned.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b3139dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical columns for one-hot encoding\n",
    "categorical_cols = ['HOME_TEAM', 'AWAY_TEAM', 'STADIUM', 'ASSIST_PLAYER', 'GOAL_SCORER_TEAM_NAME']\n",
    "\n",
    "# Load dataset and preprocessing as before...\n",
    "\n",
    "# Separate features and target variables for both 'GOALS' and 'ASSISTS'\n",
    "X = df_cleaned.drop(columns=['ASSISTS'])  # Features\n",
    "y = df_cleaned[['ASSISTS']]  # Target variables for both 'GOALS' and 'ASSISTS'\n",
    "\n",
    "# Split the data into training and testing sets for both features and targets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define a preprocessing pipeline for one-hot encoding\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68bfd5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE for ASSISTS: 0.20887291625996382\n",
      "Ridge Regression MSE for ASSISTS: 0.19056551311127715\n",
      "Lasso Regression MSE for ASSISTS: 0.6713629723400562\n",
      "ElasticNet Regression MSE for ASSISTS: 0.6713629723400562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalvi\\.conda\\envs\\InfoSys501General\\Lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression MSE for ASSISTS: 0.09244707317073171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalvi\\.conda\\envs\\InfoSys501General\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR MSE for ASSISTS: 0.16402422190581606\n",
      "XGBoost Regression MSE for ASSISTS: 0.09878874268001099\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary of regressors for different algorithms\n",
    "regressors = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'ElasticNet Regression': ElasticNet(),\n",
    "    'Random Forest Regression': RandomForestRegressor(),\n",
    "    'SVR': SVR(),\n",
    "    'XGBoost Regression': XGBRegressor()\n",
    "}\n",
    "\n",
    "# Fit and evaluate each regressor with MultiOutputRegressor\n",
    "for name, regressor in regressors.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', regressor)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    predictions = pipeline.predict(X_test)\n",
    "    mse_goals = mean_squared_error(y_test, predictions)\n",
    "    print(f\"{name} MSE for ASSISTS: {mse_goals}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc07e7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'regressor__n_estimators': 300, 'regressor__max_depth': 5, 'regressor__learning_rate': 0.1}\n",
      "Tuned XGBoost Regression MSE for ASSISTS: 0.10573751919132743\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [5, 9, 10],\n",
    "    'regressor__learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Create a pipeline with preprocessing and XGBoost Regression\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', XGBRegressor())\n",
    "])\n",
    "\n",
    "# Apply RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_grid, n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = random_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Predict on the test set with the best model\n",
    "best_model = random_search.best_estimator_\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for both goals and assists\n",
    "mse_goals = mean_squared_error(y_test, predictions)\n",
    "print(f\"Tuned XGBoost Regression MSE for ASSISTS: {mse_goals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecf5b665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned XGBoost Regression MSE for ASSISTS: 0.10766809903853986\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use the best parameters obtained from the hyperparameter tuning\n",
    "best_params = {\n",
    "    'n_estimators': 450,\n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.2\n",
    "}\n",
    "\n",
    "# Create an XGBoost regressor with the best parameters\n",
    "best_model = XGBRegressor(**best_params)\n",
    "\n",
    "# Create a pipeline with preprocessing and XGBoost Regression\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', best_model)\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for both goals and assists\n",
    "mse_goals = mean_squared_error(y_test, predictions)\n",
    "print(f\"Tuned XGBoost Regression MSE for ASSISTS: {mse_goals}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64d0d4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Assist : [1.0901728]\n"
     ]
    }
   ],
   "source": [
    "# xgboost is much faster than the random forest \n",
    "# hence we are finalising our model and choosing xgboost for better mse and faster prediction\n",
    "\n",
    "# Sample data for a single row (adjust according to your actual data)\n",
    "input_data = {\n",
    "    'HOME_TEAM': 'Real Madrid',\n",
    "    'AWAY_TEAM': 'SSC Napoli',\n",
    "    'STADIUM': 'Santiago Bernab√©u',\n",
    "    'ASSIST_PLAYER': 'David Alaba',\n",
    "    'GOAL_SCORER_TEAM_NAME': 'Real Madrid'\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the single row data\n",
    "input_df = pd.DataFrame([input_data])\n",
    "\n",
    "# Use the trained pipeline to preprocess the single row data and make predictions\n",
    "predictions = pipeline.predict(input_df)\n",
    "\n",
    "print(f\"Predicted Assist : {predictions}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "968f0ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgboost_assists_model.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(pipeline, 'xgboost_assists_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771bbb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
